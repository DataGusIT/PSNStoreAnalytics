# PSN Store Analytics - Intelig√™ncia de Mercado

> Pipeline de Engenharia de Dados automatizado para extra√ß√£o (Web Scraping), processamento (ETL) e an√°lise estrat√©gica de pre√ßos da PlayStation Store.

[![Status](https://img.shields.io/badge/Status-Conclu√≠do-success)](https://github.com/DataGusIT/psn-analytics)
[![Python](https://img.shields.io/badge/Python-3.12+-3776AB)](https://www.python.org/)
[![Playwright](https://img.shields.io/badge/Playwright-Automation-2EAD33)](https://playwright.dev/)
[![Pandas](https://img.shields.io/badge/Pandas-Data_Science-150458)](https://pandas.pydata.org/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

## Sobre o Projeto

O **PSN Store Analytics** √© uma aplica√ß√£o de Data Science e Engenharia de Dados desenvolvida para monitorar o ecossistema de pre√ßos da loja digital da PlayStation. O objetivo foi criar um sistema capaz de simular um analista de mercado, coletando dados em tempo real e transformando-os em insights financeiros para tomada de decis√£o.

Diferente de scrapers simples, este projeto implementa um pipeline completo: coleta dados de p√°ginas din√¢micas (Single Page Applications) usando automa√ß√£o de navegador, realiza a limpeza e engenharia de atributos (ETL) e persiste os dados em um hist√≥rico incremental para an√°lise de tend√™ncias e oportunidades de compra (arbitragem de pre√ßos).

## üìä Demonstra√ß√£o Visual

| Distribui√ß√£o de Pre√ßos | Top 10 Jogos Mais Caros | Melhores Oportunidades (%) |
| :---: | :---: | :---: |
| <img width="1021" height="573" alt="Image" src="https://github.com/user-attachments/assets/565525ed-a0e7-4733-8ab8-8adc91d1ce03" /> | <img width="1477" height="709" alt="Image" src="https://github.com/user-attachments/assets/11c1950d-42ef-481c-8557-be74fa7192b4" /> | <img width="1444" height="554" alt="Image" src="https://github.com/user-attachments/assets/7d74b7ff-64d4-46a4-befc-d559461c4dd5" /> |

## ‚ú® Funcionalidades

### üì° Coleta de Dados (Web Scraping)
-   **Automa√ß√£o com Playwright:** Simula√ß√£o de navegador real para renderizar p√°ginas din√¢micas (JavaScript pesado) que bibliotecas comuns n√£o conseguem acessar.
-   **Pagina√ß√£o Autom√°tica:** O rob√¥ percorre centenas de p√°ginas da loja automaticamente.
-   **Tratamento de Lazy Loading:** Algoritmo de scroll e espera inteligente (`networkidle`) para garantir o carregamento de todas as imagens e pre√ßos antes da extra√ß√£o.

### ‚öôÔ∏è Processamento (ETL)
-   **Limpeza de Dados:** Convers√£o de strings complexas (ex: "R$ 1.299,90") para tipos num√©ricos (Float) e tratamento de valores nulos.
-   **Engenharia de Atributos:** Cria√ß√£o de novas m√©tricas n√£o nativas da loja, como `Economia_Real_BRL` e `Preco_Original_Estimado`.
-   **Hist√≥rico Incremental:** Sistema de banco de dados (`.csv` append-only) que acumula dados de diferentes execu√ß√µes para an√°lise temporal.

### üìà Analytics & Insights
-   **Ranking de Pricing:** Identifica√ß√£o dos produtos "Top Tier" (Premium) e distribui√ß√£o de faixas de pre√ßo.
-   **Ca√ßador de Ofertas:** Algoritmo que destaca as maiores quedas de pre√ßo percentuais e absolutas.
-   **Visualiza√ß√£o Profissional:** Dashboards gerados com Seaborn e Matplotlib para storytelling de dados.

## Tecnologias

### Linguagem e Core
-   **Python 3.12+**
-   **Playwright** (Automa√ß√£o de Browser e Scraping)
-   **Glob & OS** (Gerenciamento de arquivos e sistema)

### Processamento e An√°lise
-   **Pandas** (Manipula√ß√£o de DataFrames e ETL)
-   **NumPy** (Computa√ß√£o num√©rica)

### Visualiza√ß√£o
-   **Matplotlib**
-   **Seaborn**
-   **Jupyter Notebook** (Ambiente de prototipagem e apresenta√ß√£o)

## Primeiros Passos

Este projeto requer Python instalado e as depend√™ncias listadas.

1.  **Clone o reposit√≥rio**
    ```bash
    git clone https://github.com/DataGusIT/psn-analytics.git
    cd psn-analytics
    ```

2.  **Configure o Ambiente Virtual**
    ```bash
    python -m venv venv
    # Windows:
    .\venv\Scripts\activate
    # Linux/Mac:
    source venv/bin/activate
    ```

3.  **Instale as Depend√™ncias**
    ```bash
    pip install -r requirements.txt
    playwright install
    ```

4.  **Execute o Pipeline Completo**
    O arquivo `main.py` executa o scraping e o ETL sequencialmente.
    ```bash
    python src/main.py
    ```

5.  **Visualize os Resultados**
    Abra o notebook na pasta `notebooks/` para ver os gr√°ficos gerados com os dados frescos.

## Aprendizados

Este projeto consolidou conhecimentos avan√ßados em:

-   **Web Scraping Moderno:** Como lidar com seletores din√¢micos, Shadow DOM e estrat√©gias anti-bot simples usando Playwright.
-   **Pipeline de Dados:** A import√¢ncia de separar as camadas de extra√ß√£o (`raw`) e processamento (`processed`) para integridade dos dados.
-   **Tratamento de Exce√ß√µes:** Cria√ß√£o de scripts resilientes que n√£o falham completamente ao encontrar um dado corrompido ou erro de rede.
-   **Storytelling com Dados:** Transforma√ß√£o de n√∫meros brutos em gr√°ficos que respondem perguntas de neg√≥cio.

## Suporte e Contato

-   **Email**: [g.moreno.souza05@gmail.com](mailto:g.moreno.souza05@gmail.com)
-   **LinkedIn**: [Gustavo Moreno](https://www.linkedin.com/in/gustavo-moreno-8a925b26a/)

## Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

<div align="center">
  Desenvolvido por Gustavo Moreno Souza
  <br><br>
  <a href="https://www.linkedin.com/in/gustavo-moreno-8a925b26a/" target="_blank">
    <img src="https://cdn-icons-png.flaticon.com/512/174/174857.png" width="24" alt="LinkedIn"/>
  </a>
</div>
